# Distributed Event Processing Platform

[![Java](https://img.shields.io/badge/Java-17-blue.svg)]()
[![Spring Boot](https://img.shields.io/badge/SpringBoot-3.3-success.svg)]()
[![Kafka](https://img.shields.io/badge/Kafka-Event%20Streaming-black.svg)]()
[![Redis](https://img.shields.io/badge/Redis-Caching-orange.svg)]()
[![Docker Compose](https://img.shields.io/badge/Docker-Compose-blue.svg)]()

ğŸ“¦ Distributed Event Processing Platform

Java â€¢ Spring Boot â€¢ Apache Kafka â€¢ Redis â€¢ Docker â€¢ AWS-ready

A high-performance, fault-tolerant, event-driven backend platform capable of processing 30K+ events/sec with retry logic, dead-letter queues, idempotency guarantees, and real-time observability.
Designed to simulate enterprise-grade ingestion pipelines similar to those used in fintech, e-commerce, supply chain, and IoT systems.

âš¡ Key Features

High-throughput ingestion with Kafka (30K+ events/sec benchmarked locally)

Idempotent processing using Redis to prevent duplicate event execution

Retry + DLQ strategy with backoff control

Production-style CI/CD structure

Clean layered architecture (Controller â†’ Service â†’ Processor â†’ Kafka)

Structured logging + metrics hooks

Docker Compose environment for local Kafka + Redis

ğŸ—ï¸ Architecture Overview
flowchart LR
    A[Producer API / External Systems] -->|HTTP/JSON| B[Ingestion Service]

    B -->|Publish| C[(Kafka Topic: events)]
    C --> D[Event Consumer]

    D -->|Idempotency Check| E[Redis Cache]

    D -->|Process Event| F[Business Logic Engine]

    F -->|Success| G[(Kafka Topic: processed-events)]
    F -->|Failure| H[(Kafka DLQ)]

    H --> I[Retry Workers]

ğŸš€ Tech Stack
Layer	Technologies
Language	Java 17
Backend Framework	Spring Boot, Spring WebFlux
Messaging	Apache Kafka, Kafka Streams
Caching / Idempotency	Redis
Containerization	Docker, Docker Compose
Build Tool	Maven
Observability	Structured JSON Logging, Prometheus-ready hooks
ğŸ› ï¸ Local Setup â€” Complete Step-By-Step Guide

This section is written for someone who knows nothing. It walks them through every single step.

âœ… 1. Install Prerequisites
Windows / macOS / Linux

Install:

Java 17 (Temurin or Oracle JDK)

Maven 3.8+

Docker Desktop

Git

Check versions:

java -version
mvn -version
docker --version
git --version

âœ… 2. Clone the repository
git clone https://github.com/bharathkumardev1/distributed-event-processing-platform.git
cd distributed-event-processing-platform

âœ… 3. Start Kafka + Redis using Docker Compose
docker-compose up -d


This spins up:

Service	Port	Description
Kafka Broker	9092	Event streaming backbone
Zookeeper	2181	Kafka coordination service
Redis	6379	Idempotency + caching

Check containers:

docker ps

âœ… 4. Build the application
mvn clean install

âœ… 5. Run the Spring Boot backend
mvn spring-boot:run


Service starts on:

http://localhost:8080


You will see Kafka + Redis connections being established in logs.

ğŸ“® API Usage (Real Examples)
â¤ 1. Publish an Event
curl -X POST http://localhost:8080/api/events \
-H "Content-Type: application/json" \
-d '{
  "eventId": "evt-10001",
  "payload": {
    "userId": 54,
    "amount": 200,
    "timestamp": "2025-01-15T10:22:09Z"
  }
}'


âœ” Writes event â†’ Kafka
âœ” Checks idempotency
âœ” Acknowledges ingestion

â¤ 2. View Processed Event Output

Consumer stores results in:

processed-events topic


You can read messages using Kafkaâ€™s console tool:

docker exec -it kafka kafka-console-consumer \
--bootstrap-server localhost:9092 \
--topic processed-events \
--from-beginning

â¤ 3. Inspect DLQ Messages
docker exec -it kafka kafka-console-consumer \
--bootstrap-server localhost:9092 \
--topic events-dlq \
--from-beginning

ğŸ”„ Retry & DLQ Flow

The system applies:

3 retries with exponential backoff

After 3 failures â†’ move to DLQ

Retry workers periodically drain DLQ and reprocess

Idempotency check ensures no duplicate processing even after retries

ğŸ”‘ Idempotency Logic

Every event has a unique ID:

eventId


Before processing an event:

if (redis.contains(eventId)) {
    skip(); // Already processed
}


After successful processing â†’ eventId is written into Redis with TTL.

This prevents:

duplicate messages

at-least-once Kafka consumer duplication

retry infinite loops

ğŸ“Š Project Structure
src/
 â””â”€â”€ main/java/com/bharath/eventplatform/
     â”œâ”€â”€ controller/      â†’ API endpoints
     â”œâ”€â”€ producer/        â†’ Kafka producers
     â”œâ”€â”€ consumer/        â†’ Kafka consumers
     â”œâ”€â”€ service/         â†’ Business logic
     â”œâ”€â”€ config/          â†’ Kafka/Redis configs
     â””â”€â”€ model/           â†’ DTOs, Event models

âš™ï¸ Scaling Notes

The system is designed for:

Horizontal scaling using Kafka partitions

Stateless microservices (safe to replicate N times)

Redis remains the single source of truth for idempotency

In production â†’ ECS, EKS, Lambda, or Kubernetes HPA

Benchmarks (local):

Batch Size	Throughput
1	~8K/sec
10	~22K/sec
50	~32K/sec
ğŸ§ª Testing

Includes:

Unit tests (JUnit)

Integration tests (TestContainers)

Kafka + Redis integration workflow tests

To run:

mvn test

ğŸ“˜ Future Enhancements (Roadmap)

Add LLM-driven enrichment (OpenAI / Claude)

Add partition rebalancing metrics

Add gRPC ingestion API

Add multi-region failover

Add distributed tracing (Jaeger + OpenTelemetry)

ğŸ¤ Contributing

Pull requests are welcome.
Open issues for enhancements, bugs, or feature requests.

ğŸ“ License

MIT License.

â­ If you found this useful, star the repo!
